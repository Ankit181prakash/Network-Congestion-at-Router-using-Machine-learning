# Network-Congestion-at-Router-using-Machine-learning
Packet loss is a key issue in transmission, lowering system performance. Early congestion detection can prevent it by controlling packet generation. Traditional protocols act rigidly, ignoring context. Machine Learning enables adaptive, data-driven decisions, improving efficiency and reliability.
Most TCP congestion control algorithms follow the end-to-end principle, meaning they operate either at the sender or the receiver side. In contrast, the proposed model is designed to function at the router level. It learns queue behavior, such as the number of packets currently in the queue, the remaining space available, and the average queue size, by applying supervised learning techniques. Once the training process is complete, the model can predict potential congestion in the router before packet loss occurs.

To build this ML-based model, several steps are required.

Problem Formulation:
The first step is to define the problem clearly. Network congestion is a critical challenge, occurring when the volume of data generated exceeds the available bandwidth. This situation forces excess packets to be stored in the buffers of intermediate devices such as routers. If the buffer space becomes insufficient, packets are dropped due to overflow. Typically, routers drop packets to alleviate congestion without notifying the sender, leaving the sender unaware of the exact cause of packet loss. Such loss may result from either buffer overflow or link errors. Additionally, when the end-to-end communication path includes a bottleneck link, congestion becomes more likely. To address these challenges, it is essential to detect possible congestion at the router before packet loss happens, and Machine Learning offers an effective solution.

Generating Training Dataset:
The next step is to gather network data to train the model. This data can be collected in two ways: offline or online. In the offline approach, a large dataset is gathered in advance, which is crucial for training purposes. In the online approach, live data generated by a network simulator is fed into the ML model, which allows for real-time testing and performance evaluation.
